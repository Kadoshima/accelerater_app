# ソニフィケーション技術仕様書

## 1. 概要

本仕様書は、v03実験で使用する高度なソニフィケーション（可聴化）技術の詳細を定義する。従来の単純なメトロノーム音を超えて、歩行の多次元的な情報を音響的に表現し、直感的かつ効果的なフィードバックを提供する。

## 2. ソニフィケーションの基本原理

### 2.1 マッピング戦略

歩行パラメータから音響パラメータへのマッピングは以下の原則に従う：

1. **直感性**: 身体感覚と音響表現の自然な対応
2. **識別性**: 異なる情報が明確に区別可能
3. **快適性**: 長時間使用でも疲労しない音響設計
4. **適応性**: 個人の音楽的嗜好・聴覚特性への対応

### 2.2 音響パラメータ

利用可能な音響パラメータ：
- **リズム**: テンポ、拍子、シンコペーション
- **ピッチ**: 基本周波数、音程、音階
- **ハーモニー**: 和音、進行、緊張と解決
- **音色**: 倍音構成、エンベロープ、フィルタ
- **空間**: パンニング、リバーブ、距離感
- **強度**: 音量、ダイナミクス、アクセント

## 3. ソニフィケーションモード詳細

### 3.1 リズムモード（基本）

**目的**: 歩行テンポの誘導と安定化

**実装**:
```
- 基本ビート: 歩行周期に同期したクリック音
- テンポ範囲: 80-140 BPM（歩数/分）
- 音源: ウッドブロック、カスタネット等の自然音
- 適応制御: 現在のケイデンス±10%の範囲で調整
```

### 3.2 ハーモニーモード（歩行安定性）

**目的**: 左右バランスと歩行対称性の可聴化

**実装**:
```
歩行対称性 → 和音の協和度
- 完全対称（CV<5%）: 長三和音（C-E-G）
- 軽度非対称（CV 5-10%）: 短三和音（C-Eb-G）
- 中度非対称（CV 10-15%）: sus4和音（C-F-G）
- 重度非対称（CV>15%）: 減三和音（C-Eb-Gb）

左右バランス → ステレオ定位
- 右荷重優位: 右チャンネル強調
- 左荷重優位: 左チャンネル強調
- バランス良好: センター定位
```

### 3.3 音色モード（運動効率）

**目的**: エネルギー効率と運動の滑らかさの表現

**実装**:
```
運動効率 → 音色の明るさ（スペクトル重心）
- 高効率: 明るい音色（高周波成分豊富）
- 中効率: 中間的音色
- 低効率: 暗い音色（低周波成分中心）

加速度の滑らかさ → 音の粒状性
- 滑らか: レガート奏法
- 普通: 通常奏法
- 不規則: スタッカート奏法

実装音源:
- シンセサイザー（減算合成）
- フィルタカットオフ: 200-5000Hz可変
- エンベロープADSR動的制御
```

### 3.4 統合モード

**目的**: 複数パラメータの同時表現

**実装例**:
```
レイヤー構造:
1. ベースレイヤー: リズム（歩行テンポ）
2. ハーモニーレイヤー: 安定性情報
3. メロディレイヤー: 進行方向・速度変化
4. アンビエントレイヤー: 全体的な運動の質

音楽的構造:
- キー: 個人の好みに応じて選択（C Major/A minorデフォルト）
- 進行: I-IV-V-I（安定時）、ii-V-I（改善時）
- テクスチャ: 歩行質に応じて厚み変化
```

### 3.5 個別最適化モード

**目的**: AIが学習した個人特性に基づく最適フィードバック

**実装**:
```
パーソナライゼーション要素:
1. 音楽的嗜好
   - ジャンル（クラシック/ポップ/アンビエント等）
   - 楽器選択（ピアノ/ギター/シンセ等）
   - リズムパターン（4/4, 3/4, 6/8等）

2. 聴覚特性
   - 周波数応答補正
   - ダイナミックレンジ調整
   - マスキング回避

3. 反応特性
   - フィードバックゲイン個別調整
   - 遅延補償
   - 変化率の最適化
```

## 4. 技術実装

### 4.1 オーディオエンジン

**要求仕様**:
- サンプリングレート: 48kHz
- ビット深度: 24bit
- レイテンシ: <20ms（知覚閾値以下）
- 同時発音数: 16音以上

**実装技術**:
- Core Audio (iOS) / AAudio (Android)
- リアルタイムオーディオ合成
- マルチスレッド処理

### 4.2 信号処理

**リアルタイム解析**:
```python
# 疑似コード
def process_gait_to_sound(sensor_data):
    # 歩行イベント検出
    events = detect_gait_events(sensor_data)
    
    # パラメータ抽出
    symmetry = calculate_symmetry(events)
    efficiency = estimate_efficiency(sensor_data)
    stability = assess_stability(sensor_data)
    
    # ソニフィケーション
    audio = sonify_parameters(
        symmetry=symmetry,
        efficiency=efficiency,
        stability=stability,
        mode=current_mode,
        profile=user_profile
    )
    
    return audio
```

### 4.3 適応アルゴリズム

**学習プロセス**:
1. 初期プロファイリング（1週間）
2. 応答パターン分析
3. 最適パラメータ探索（強化学習）
4. 継続的微調整

## 5. ユーザーインターフェース

### 5.1 視覚フィードバック連携

ソニフィケーションを補完する視覚表示：
- リアルタイムスペクトログラム
- 歩行パラメータのグラフ表示
- 音楽的表現の可視化（楽譜風表示）

### 5.2 カスタマイズオプション

ユーザー設定可能項目：
- 音量バランス（各レイヤー独立）
- 音色プリセット選択
- フィードバック感度
- ミュートオプション（特定パラメータ）

## 6. 評価指標

### 6.1 音響品質評価

- **客観的指標**: THD+N、S/N比、周波数応答
- **主観的指標**: 音質評価尺度、疲労度評価

### 6.2 フィードバック効果評価

- **即時性**: 刺激-反応時間
- **識別性**: パラメータ変化の知覚精度
- **学習性**: 習熟に要する時間

## 7. 今後の拡張

### 7.1 環境適応

- 環境音のリアルタイム分析
- 騒音下での自動ゲイン調整
- 空間音響を利用したARオーディオ

### 7.2 マルチモーダル統合

- 触覚フィードバックとの連携
- 音楽療法プロトコルの統合
- VR/AR環境での没入型体験

---

最終更新日: 2025年6月9日